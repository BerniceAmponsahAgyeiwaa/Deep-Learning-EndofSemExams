{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T14:56:54.000297Z",
     "start_time": "2025-12-17T14:56:50.700107Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "metadata_path = \"../data/metadata.csv\"\n",
    "df = pd.read_csv(metadata_path)\n",
    "\n",
    "df.head()\n"
   ],
   "id": "190473195e5205d3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                            filepath emotion  gender\n",
       "0  ../data/RADVESS/Actor_16/03-01-05-01-02-01-16.wav   angry  female\n",
       "1  ../data/RADVESS/Actor_16/03-01-05-02-01-01-16.wav   angry  female\n",
       "2  ../data/RADVESS/Actor_16/03-01-04-01-01-02-16.wav     sad  female\n",
       "3  ../data/RADVESS/Actor_16/03-01-04-02-02-02-16.wav     sad  female\n",
       "4  ../data/RADVESS/Actor_16/03-01-03-02-02-02-16.wav   happy  female"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepath</th>\n",
       "      <th>emotion</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data/RADVESS/Actor_16/03-01-05-01-02-01-16.wav</td>\n",
       "      <td>angry</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../data/RADVESS/Actor_16/03-01-05-02-01-01-16.wav</td>\n",
       "      <td>angry</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../data/RADVESS/Actor_16/03-01-04-01-01-02-16.wav</td>\n",
       "      <td>sad</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../data/RADVESS/Actor_16/03-01-04-02-02-02-16.wav</td>\n",
       "      <td>sad</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../data/RADVESS/Actor_16/03-01-03-02-02-02-16.wav</td>\n",
       "      <td>happy</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T14:57:11.926260Z",
     "start_time": "2025-12-17T14:57:11.891649Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "df[\"emotion_label\"] = label_encoder.fit_transform(df[\"emotion\"])\n",
    "\n",
    "num_classes = df[\"emotion_label\"].nunique()\n",
    "num_classes\n"
   ],
   "id": "393188788ed62380",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T15:02:54.505969Z",
     "start_time": "2025-12-17T15:02:54.486457Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# mfcc extraction\n",
    "class RAVDESSDataset(Dataset):\n",
    "    def __init__(self, df, max_len=200):\n",
    "        self.df = df\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def pad(self, x):\n",
    "        if x.shape[1] < self.max_len:\n",
    "            pad_width = self.max_len - x.shape[1]\n",
    "            x = np.pad(x, ((0,0),(0,pad_width)), mode='constant')\n",
    "        else:\n",
    "            x = x[:, :self.max_len]\n",
    "        return x\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        path = row[\"filepath\"]\n",
    "        y = row[\"emotion_label\"]\n",
    "\n",
    "        audio, sr = librosa.load(path, sr=16000)\n",
    "        mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=40)\n",
    "        mfcc = self.pad(mfcc)\n",
    "\n",
    "        return torch.tensor(mfcc, dtype=torch.float32).T, torch.tensor(y)\n"
   ],
   "id": "e6fdced4544b59ab",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T15:03:09.272833Z",
     "start_time": "2025-12-17T15:03:09.254153Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#train test split and loaders\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, stratify=df[\"emotion_label\"])\n",
    "\n",
    "train_ds = RAVDESSDataset(train_df)\n",
    "test_ds = RAVDESSDataset(test_df)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_ds, batch_size=16)\n"
   ],
   "id": "4bc12033a66f8680",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T15:03:10.382660Z",
     "start_time": "2025-12-17T15:03:10.362242Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# LSTM model\n",
    "class LSTMBaseline(nn.Module):\n",
    "    def __init__(self, input_dim=40, hidden_dim=64, num_classes=4):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = out[:, -1, :]  # last timestep\n",
    "        return self.fc(out)\n",
    "\n",
    "model = LSTMBaseline(num_classes=num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
   ],
   "id": "ce86ec99b5405a1",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T15:06:09.717924Z",
     "start_time": "2025-12-17T15:04:19.114610Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# model training\n",
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "\n",
    "    for X, y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X)\n",
    "        loss = criterion(outputs, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader):.4f}\")\n"
   ],
   "id": "387cd0608c724250",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 1.3528\n",
      "Epoch 2/10, Loss: 1.3548\n",
      "Epoch 3/10, Loss: 1.3555\n",
      "Epoch 4/10, Loss: 1.3529\n",
      "Epoch 5/10, Loss: 1.3561\n",
      "Epoch 6/10, Loss: 1.3544\n",
      "Epoch 7/10, Loss: 1.3533\n",
      "Epoch 8/10, Loss: 1.3575\n",
      "Epoch 9/10, Loss: 1.3530\n",
      "Epoch 10/10, Loss: 1.3542\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T15:22:35.439658Z",
     "start_time": "2025-12-17T15:22:32.269370Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# evakuate and save predictions of the baseline lstm\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "all_paths = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch, (X, y) in enumerate(test_loader):\n",
    "        outputs = model(X)\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "\n",
    "        all_preds.extend(preds.numpy())\n",
    "        all_labels.extend(y.numpy())\n",
    "\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "f1 = f1_score(all_labels, all_preds, average=\"weighted\")\n",
    "\n",
    "print(\"Baseline Model Accuracy:\", accuracy)\n",
    "print(\"Baseline Model F1 Score:\", f1)\n"
   ],
   "id": "dd9f3afcda2cdc1c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Model Accuracy: 0.28888888888888886\n",
      "Baseline Model F1 Score: 0.12950191570881225\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T15:22:44.337995Z",
     "start_time": "2025-12-17T15:22:44.299372Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# save model\n",
    "model_path = \"../models/lstm_baseline.pth\"\n",
    "torch.save(model.state_dict(), model_path)\n",
    "model_path\n"
   ],
   "id": "4855bda8eccf5c46",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../models/lstm_baseline.pth'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T15:23:15.658031Z",
     "start_time": "2025-12-17T15:23:15.501846Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# save predictions\n",
    "pred_df = test_df.copy()\n",
    "pred_df[\"predicted\"] = [label_encoder.inverse_transform([p])[0] for p in all_preds]\n",
    "\n",
    "output_path = \"../results/lstm_predictions.csv\"\n",
    "pred_df.to_csv(output_path, index=False)\n",
    "output_path\n"
   ],
   "id": "af06edfccb2a3b62",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../results/lstm_predictions.csv'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "266deb95563d830a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
